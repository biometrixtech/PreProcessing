# A template that creates monitoring for a preprocessing pipeline
# Version: da39a3ee5e6b4b0d3255bfef95601890afd80709
#
# Copyright 2018 Melon Software Ltd (UK), all rights reserved.  Used under license.
#
AWSTemplateFormatVersion: "2010-09-09"
Description: "Creates monitoring systems for the pre-processing pipeline"

Parameters:

    # Environment name
    Environment:
        Type: "String"
        Description: "The name of the environment"

    EfsId:
        Type: "String"
        Description: "The id of the Elastic File System"

    BatchJobQueueArn:
        Type: "String"
        Description: "The ARN of the Job Queue"

    BatchComputeEnvironmentArn:
        Type: "String"
        Description: "The ARN of the ComputeEnvironment"

    BatchComputeEnvironmentEcsClusterName:
        Type: "String"
        Description: "The name of the ComputeEnvironment ECS Cluster"

    PipelineStateMachineArn:
        Type: "String"
        Description: "The ARN of the Pipeline State Machine"

    AutoscalingSchedule:
        Type: "String"
        Default: ""
        Description: "A definition string for autoscaling"

Conditions:
    CreateAutoscaling: { "Fn::Not": [ { "Fn::Equals": [ { Ref: "AutoscalingSchedule" }, "" ] } ] }

Mappings:
    TemplateVersion:
        Self: { Commit: "da39a3ee5e6b4b0d3255bfef95601890afd80709" }

Resources:

    ##########################################################################################################
    ##  LOGGING
    ##########################################################################################################

    CloudwatchLogsGroup:
        Type: "AWS::Logs::LogGroup"
        Properties:
            LogGroupName: { "Fn::Sub": "/biometrix/preprocessing/${Environment}" }
            RetentionInDays: 14

    ##########################################################################################################
    ##  MONITORING
    ##########################################################################################################

    LambdaMonitoringRole:
        Type: "AWS::IAM::Role"
        Properties:
            AssumeRolePolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Effect: "Allow"
                    Principal: { Service: [ "lambda.amazonaws.com" ] }
                    Action: "sts:AssumeRole"
            ManagedPolicyArns:
              - "arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole"
            Policies:
              - PolicyName: "default"
                PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Action:
                          - "cloudwatch:PutMetricData"
                        Effect: "Allow"
                        Resource: "*"

                      - Action:
                          - "batch:DescribeComputeEnvironments"
                          - "batch:ListJobs"
                          - "ecs:ListContainerInstances"
                          - "ecs:DescribeContainerInstances"
                          - "ec2:DescribeInstances"
                          - "elasticfilesystem:DescribeFileSystems"
                          - "states:ListExecutions"
                        Effect: "Allow"
                        Resource: "*"
            RoleName: { "Fn::Sub": "preprocessing-${Environment}-monitor-lambda-${AWS::Region}" }

    MonitoringLambda:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: |
                    import boto3, datetime, itertools, os, re

                    cloudwatch_client = boto3.client('cloudwatch')
                    batch_client = boto3.client('batch')
                    ec2_client = boto3.client('ec2')
                    ecs_client = boto3.client('ecs')
                    efs_client = boto3.client('efs')
                    sfn_client = boto3.client('stepfunctions')

                    def handler(_, __):
                        batch_desired_vcpus = batch_client.describe_compute_environments(computeEnvironments=[os.environ['BATCH_COMPUTE_ENVIRONMENT']])['computeEnvironments'][0]['computeResources']['desiredvCpus']
                        put_metric('BatchComputeEnvironmentDesiredCpus', batch_desired_vcpus)

                        try:
                            container_instance_arns = [arn for arn in ecs_client.list_container_instances(cluster=os.environ['BATCH_ECS_CLUSTER'])['containerInstanceArns']]
                            ec2_instances = [instance['ec2InstanceId'] for instance in ecs_client.describe_container_instances(cluster=os.environ['BATCH_ECS_CLUSTER'], containerInstances=container_instance_arns)['containerInstances']]
                            data = ec2_client.describe_instances(InstanceIds=ec2_instances, Filters=[{'Name': 'instance-state-name', 'Values': ['running']}])['Reservations']
                            instance_data = {'c4\.8xlarge': 36, "m4\.10xlarge": 40, '..\.32xlarge': 128, '..\.16xlarge': 64, '..\.8xlarge': 32, '..\.4xlarge': 16, '..\.2xlarge': 8, '..\.xlarge': 4, '..\.large': 2, '..\.medium': 1, }
                            def get_cpu(t):
                                for r, v in instance_data.items():
                                    if re.match(r, t):
                                        return v
                            batch_actual_cpus = sum([get_cpu(instance['InstanceType']) for reservation in data for instance in reservation['Instances']])
                            put_metric('BatchComputeEnvironmentActualCpus', batch_actual_cpus)
                        except:
                            pass

                        # Batch jobs by status
                        for group, statuses in {'SCHEDULED': ['SUBMITTED', 'PENDING', 'RUNNABLE', 'STARTING'], 'RUNNING': ['RUNNING'], 'SUCCEEDED': ['SUCCEEDED'], 'FAILED': ['FAILED']}.items():
                            group_jobs = []
                            for status in statuses:
                                jobs = batch_jobs_by_job(status)
                                put_metric('BatchJobQueueCount', len(jobs), {'Status': status})
                                group_jobs += jobs
                            for job_name, jobs in itertools.groupby(sorted(group_jobs)):
                                put_metric('BatchJobQueueCount', len(list(jobs)), {'Status': group, 'Job': job_name})

                        # EFS filsystem size
                        data = efs_client.describe_file_systems(FileSystemId=os.environ['BATCH_EFS_ID'])['FileSystems'][0]
                        put_metric('BatchEfsSize', data['SizeInBytes']['Value'], unit='Bytes')

                        # SFN executions
                        executions = [ex['status'] for ex in list_sfn_executions() if ex['status'] == 'RUNNING' or (
                                datetime.datetime.now() - ex['stopDate'].replace(tzinfo=None)).total_seconds() < 60 * 5]
                        for status in ['RUNNING', 'SUCCEEDED', 'FAILED', 'TIMED_OUT', 'ABORTED']:
                            put_metric('StepFunctionsExecutions', executions.count(status), {'Status': status})

                    def batch_jobs_by_job(status, token=''):
                        jobs = batch_client.list_jobs(jobQueue=os.environ['BATCH_JOB_QUEUE'], jobStatus=status, nextToken=token)
                        return [job['jobName'].split('-')[4] for job in jobs['jobSummaryList']] + (
                            batch_jobs_by_job(status, jobs['nextToken']) if 'nextToken' in jobs and jobs['nextToken'] else [])

                    def list_sfn_executions(token=None):
                        if token is not None:
                            res = sfn_client.list_executions(stateMachineArn=os.environ['STATE_MACHINE_ARN'], nextToken=token)
                        else:
                            res = sfn_client.list_executions(stateMachineArn=os.environ['STATE_MACHINE_ARN'])
                        return res['executions'] + (list_sfn_executions(res['nextToken']) if 'nextToken' in res and res['nextToken'] else [])

                    def put_metric(metric_name, value, dimensions={}, unit='None'):
                        dimensions = {**{'Environment': os.environ['ENVIRONMENT']}, **dimensions}
                        cloudwatch_client.put_metric_data(
                            Namespace='Preprocessing',
                            MetricData=[{
                                'MetricName': metric_name,
                                'Dimensions': [{'Name': k, 'Value': v} for k, v in dimensions.items()],
                                'Timestamp': datetime.datetime.utcnow(),
                                'Value': value,
                                'Unit': unit
                            }]
                        )

            Environment:
                Variables:
                    ENVIRONMENT: { Ref: "Environment" }
                    BATCH_COMPUTE_ENVIRONMENT: { Ref: "BatchComputeEnvironmentArn" }
                    BATCH_ECS_CLUSTER: { Ref: "BatchComputeEnvironmentEcsClusterName" }
                    BATCH_JOB_QUEUE: { Ref: "BatchJobQueueArn" }
                    BATCH_EFS_ID: { Ref: "EfsId" }
                    STATE_MACHINE_ARN: { Ref: "PipelineStateMachineArn" }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaMonitoringRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-monitor" }
            Tags:
              - { Key: "Name", Value: { "Fn::Sub": "preprocessing-${Environment}-monitor" } }
              - { Key: "Management", Value: "managed" }
              - { Key: "Project", Value: "preprocessing" }
              - { Key: "Environment", Value: { Ref: "Environment" } }

    MonitoringLambdaScheduledRule:
        Type: "AWS::Events::Rule"
        Properties:
            Description: "ScheduledRule"
            ScheduleExpression: "rate(1 minute)"
            State: "ENABLED"
            Targets:
              - Arn: { "Fn::GetAtt": [ "MonitoringLambda", "Arn" ] }
                Id: "TargetFunctionV1"

    MonitoringLambdaInvokePermission:
        Type: "AWS::Lambda::Permission"
        Properties:
            FunctionName: { Ref: "MonitoringLambda" }
            Action: "lambda:InvokeFunction"
            Principal: "events.amazonaws.com"
            SourceArn: { "Fn::GetAtt": [ "MonitoringLambdaScheduledRule", "Arn" ] }

    ##########################################################################################################
    ##  DASHBOARD
    ##########################################################################################################

    CloudWatchDashboard:
        Type: "AWS::CloudWatch::Dashboard"
        Properties:
            DashboardName: { "Fn::Sub": "preprocessing-${Environment}-${AWS::Region}" }
            DashboardBody: !Sub |
                { "widgets":[
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 0,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchComputeEnvironmentDesiredCpus",
                                    "Environment", "${Environment}",
                                    { "label": "Desired" }
                                ],
                                [ ".", "BatchComputeEnvironmentActualCpus", ".", ".", { "label": "Actual" } ]
                            ],
                            "period": 60,
                            "stat": "Average",
                            "region": "${AWS::Region}",
                            "title": "Compute Cluster CPUs",
                            "yAxis": {
                                "left": {
                                    "min": 0
                                }
                            }
                        }
                    },
                    {
                        "type":"metric",
                        "x": 12,
                        "y": 0,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchJobQueueCount",
                                    "Environment", "${Environment}",
                                    "Status", "SUBMITTED",
                                    { "label": "Submitted" }
                                ],
                                [ ".", ".", ".", ".", ".", "PENDING", { "label": "Pending" } ],
                                [ ".", ".", ".", ".", ".", "RUNNABLE", { "label": "Runnable" } ],
                                [ ".", ".", ".", ".", ".", "STARTING", { "label": "Starting" } ],
                                [ ".", ".", ".", ".", ".", "RUNNING", { "label": "Running" } ]
                            ],
                            "period": 60,
                            "stacked": true,
                            "stat": "Average",
                            "region": "${AWS::Region}",
                            "title": "Batch Jobs by Status",
                            "yAxis": {
                                "left": {
                                    "min": 0
                                }
                            }
                        }
                    },
                    {
                        "type":"metric",
                        "x": 0,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchJobQueueCount",
                                    "Environment", "${Environment}",
                                    "Status", "SCHEDULED",
                                    "Job", "downloadandchunk"
                                ],
                                [ ".", ".", ".", ".", ".", ".", ".", "transformandplacement" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "sessionprocess2" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "scoring" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatesession" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatetwomin" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatedateuser" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregateprogcomp" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregateprogcompdate" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregateteam" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatetraininggroup" ]
                            ],
                            "period": 60,
                            "stacked": true,
                            "stat": "Average",
                            "region": "${AWS::Region}",
                            "title": "Scheduled Batch Jobs by Job Type",
                            "yAxis": {
                                "left": {
                                    "min": 0
                                }
                            }
                        }
                    },
                    {
                        "type":"metric",
                        "x": 6,
                        "y": 6,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchJobQueueCount",
                                    "Environment", "${Environment}",
                                    "Status", "RUNNING",
                                    "Job", "downloadandchunk"
                                ],
                                [ ".", ".", ".", ".", ".", ".", ".", "transformandplacement" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "sessionprocess2" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "scoring" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatesession" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatetwomin" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatedateuser" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregateprogcomp" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregateprogcompdate" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregateteam" ],
                                [ ".", ".", ".", ".", ".", ".", ".", "aggregatetraininggroup" ]
                            ],
                            "period": 60,
                            "stacked": true,
                            "stat": "Average",
                            "region": "${AWS::Region}",
                            "title": "Running Batch Jobs by Job Type",
                            "yAxis": {
                                "left": {
                                    "min": 0
                                }
                            }
                        }
                    },
                    {
                        "type":"metric",
                        "x": 18,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchJobQueueCount",
                                    "Environment", "${Environment}",
                                    "Status", "SUCCEEDED",
                                    { "label": "Succeeded" }
                                ],
                                [ ".", ".", ".", ".", ".", "FAILED", { "label": "Failed" } ]
                            ],
                            "period": 60,
                            "stat": "Average",
                            "region": "${AWS::Region}",
                            "title": "Recently completed jobs",
                            "view": "singleValue"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 12,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "StepFunctionsExecutions",
                                    "Environment", "${Environment}",
                                    "Status", "RUNNING",
                                    { "label": "Currently running" }
                                ],
                                [ ".", ".", ".", ".", ".", "SUCCEEDED", { "yAxis": "right", "label": "Succeeded (last 5 mins)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "StepFunctions executions (success)",
                            "view": "timeSeries"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 12,
                        "y": 12,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "StepFunctionsExecutions",
                                    "Environment", "${Environment}",
                                    "Status", "FAILED",
                                    { "label": "Failed (last 5 mins)" }
                                ],
                                [ ".", ".", ".", ".", ".", "ABORTED", { "label": "Aborted (last 5 mins)" } ],
                                [ ".", ".", ".", ".", ".", "TIMED_OUT", { "label": "Timed out (last 5 mins)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "StepFunctions executions (failure)",
                            "view": "timeSeries"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 18,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchEfsSize",
                                    "Environment", "${Environment}"
                                ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "EFS filesystem size",
                            "view": "singleValue"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 18,
                        "width": 18,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "AWS/ECS", "CPUReservation", "ClusterName", "${BatchComputeEnvironmentEcsClusterName}", { "stat": "Maximum", "color": "#7B241C", "label": "CPU Reserved" } ],
                                [ ".", "CPUUtilization", ".", ".", { "stat": "Maximum", "color": "#C0392B", "label": "CPU Utilised (maximum)" } ],
                                [ "...", { "stat": "Average", "color": "#f7b6d2", "label": "CPU Utilised (average)" } ],
                                [ ".", "MemoryReservation", ".", ".", { "stat": "Maximum", "color": "#1D8348", "yAxis": "right", "label": "Memory Reserved" } ],
                                [ ".", "MemoryUtilization", ".", ".", { "stat": "Maximum", "color": "#2ECC71", "yAxis": "right", "label": "Memory Utilised (maximum)" } ],
                                [ "...", { "stat": "Average", "color": "#ABEBC6", "yAxis": "right", "label": "Memory Utilised (average)" } ]
                            ],
                            "region": "us-west-2",
                            "period": 300,
                            "title": "Task CPU / Memory"
                        }
                    },
                    {
                        "type":"metric",
                        "x": 0,
                        "y": 24,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchJobScheduleLatency",
                                    "Environment", "${Environment}",
                                    { "label": "Average" }
                                ],
                                [ ".", ".", ".", ".", "Job", "downloadandchunk" ],
                                [ ".", ".", ".", ".", ".", "transformandplacement" ],
                                [ ".", ".", ".", ".", ".", "sessionprocess2" ],
                                [ ".", ".", ".", ".", ".", "scoring" ],
                                [ ".", ".", ".", ".", ".", "aggregatesession" ],
                                [ ".", ".", ".", ".", ".", "aggregatetwomin" ],
                                [ ".", ".", ".", ".", ".", "aggregatedateuser" ],
                                [ ".", ".", ".", ".", ".", "aggregateprogcomp" ],
                                [ ".", ".", ".", ".", ".", "aggregateprogcompdate" ],
                                [ ".", ".", ".", ".", ".", "aggregateteam" ],
                                [ ".", ".", ".", ".", ".", "aggregatetraininggroup" ]
                            ],
                            "period": 60,
                            "stat": "Average",
                            "region": "${AWS::Region}",
                            "title": "Batch Latency"
                        }
                    },
                    {
                        "type":"metric",
                        "x": 12,
                        "y": 24,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [
                                    "Preprocessing",
                                    "BatchJobProcessTime",
                                    "Environment", "${Environment}",
                                    "Job", "downloadandchunk"
                                ],
                                [ ".", ".", ".", ".", ".", "transformandplacement" ],
                                [ ".", ".", ".", ".", ".", "sessionprocess2" ],
                                [ ".", ".", ".", ".", ".", "scoring" ],
                                [ ".", ".", ".", ".", ".", "aggregatesession" ],
                                [ ".", ".", ".", ".", ".", "aggregatetwomin" ],
                                [ ".", ".", ".", ".", ".", "aggregatedateuser" ],
                                [ ".", ".", ".", ".", ".", "aggregateprogcomp" ],
                                [ ".", ".", ".", ".", ".", "aggregateprogcompdate" ],
                                [ ".", ".", ".", ".", ".", "aggregateteam" ],
                                [ ".", ".", ".", ".", ".", "aggregatetraininggroup" ]
                            ],
                            "period": 60,
                            "stat": "Average",
                            "region": "${AWS::Region}",
                            "title": "Batch Process Time"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 30,
                        "width": 12,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [
                                    "AWS/DynamoDB", "ProvisionedWriteCapacityUnits",
                                    "TableName", "preprocessing-${Environment}-ingest-sessions",
                                    { "period": 300, "label": "Provisioned WCU" }
                                ],
                                [ ".", "ConsumedWriteCapacityUnits", ".", ".", { "period": 60, "label": "Consumed WCU" } ],
                                [
                                    ".", "ThrottledRequests", ".", ".", "Operation", "UpdateItem",
                                    { "period": 60, "yAxis": "right", "stat": "Sum", "label": "Throttled writes" }
                                ]
                            ],
                            "region": "${AWS::Region}",
                            "yAxis": {
                                "left": {
                                    "min": 0
                                },
                                "right": {
                                    "min": 0
                                }
                            },
                            "title": "DynamoDB - Sessions table"
                        }
                    }
                ] }

    ##########################################################################################################
    ##  SCHEDULED AUTOSCALING
    ##########################################################################################################

    LambdaAutoscalingRole:
        Type: "AWS::IAM::Role"
        Properties:
            AssumeRolePolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Effect: "Allow"
                    Principal: { Service: [ "lambda.amazonaws.com" ] }
                    Action: "sts:AssumeRole"
            ManagedPolicyArns:
              - "arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole"
            Policies:
              - PolicyName: "default"
                PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Action:
                          - "batch:DescribeComputeEnvironments"
                          - "batch:UpdateComputeEnvironment"
                        Effect: "Allow"
                        Resource: "*"
            RoleName: { "Fn::Sub": "preprocessing-${Environment}-autoscaling-lambda-${AWS::Region}" }
        Condition: "CreateAutoscaling"

    AutoscalingLambda:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: |
                    import boto3, json, os
                    from datetime import datetime

                    def handler(_, __):
                        schedule = json.loads(os.environ['AUTOSCALING_SCHEDULE'])
                        if not isinstance(schedule, dict) or not schedule:
                            print('Nothing to do')
                            # return
                            schedule = {
                                '00:00-13:00': 0,
                                '13:00-23:00': 4,
                                '23:00-24:00': 0,
                            }

                        min_capacity = parse_schedule(schedule)
                        if min_capacity is None:
                            print('No capacity scheduled')
                            return
                        print('Desired min capacity = {}'.format(min_capacity))

                        batch_client = boto3.client('batch')
                        compute_environment = batch_client.describe_compute_environments(
                            computeEnvironments=[os.environ['BATCH_COMPUTE_ENVIRONMENT']])['computeEnvironments'][0]['computeResources']
                        print(compute_environment)

                        new_desired_capacity = max(min_capacity, compute_environment['desiredvCpus'])
                        print('Current capacity is {}/{}/{}, changing to {}/{}/{}'.format(
                            compute_environment['minvCpus'],
                            compute_environment['desiredvCpus'],
                            compute_environment['maxvCpus'],
                            min_capacity,
                            new_desired_capacity,
                            compute_environment['maxvCpus']
                        ))

                        batch_client.update_compute_environment(
                            computeEnvironment=os.environ['BATCH_COMPUTE_ENVIRONMENT'],
                            computeResources={'minvCpus': min_capacity, 'desiredvCpus': new_desired_capacity},
                        )

                    def parse_schedule(schedule):
                        t_now = datetime.now().time()
                        for timerange, capacity in schedule.items():
                            start, finish = timerange.split('-')
                            start = datetime.strptime(start, '%H:%M').time()
                            finish = datetime.strptime(finish, '%H:%M').time()
                            if start < t_now < finish:
                                return capacity
                        return None

            Environment:
                Variables:
                    AUTOSCALING_SCHEDULE: { Ref: "AutoscalingSchedule" }
                    BATCH_COMPUTE_ENVIRONMENT: { Ref: "BatchComputeEnvironmentArn" }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaAutoscalingRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-autoscaling" }
            Tags:
              - { Key: "Name", Value: { "Fn::Sub": "preprocessing-${Environment}-pipeline-autoscaling" } }
              - { Key: "Management", Value: "managed" }
              - { Key: "Project", Value: "preprocessing" }
              - { Key: "Environment", Value: { Ref: "Environment" } }
        Condition: "CreateAutoscaling"

    AutoscalingLambdaScheduledRule:
        Type: "AWS::Events::Rule"
        Properties:
            Description: "ScheduledRule"
            ScheduleExpression: "cron(0 * * * ? *)"
            State: "ENABLED"
            Targets:
              - Arn: { "Fn::GetAtt": [ "AutoscalingLambda", "Arn" ] }
                Id: "TargetFunctionV1"
        Condition: "CreateAutoscaling"

    AutoscalingLambdaInvokePermission:
        Type: "AWS::Lambda::Permission"
        Properties:
            FunctionName: { Ref: "AutoscalingLambda" }
            Action: "lambda:InvokeFunction"
            Principal: "events.amazonaws.com"
            SourceArn: { "Fn::GetAtt": [ "AutoscalingLambdaScheduledRule", "Arn" ] }
        Condition: "CreateAutoscaling"
