# A template that creates the ingest system for sensor data
# Version: da39a3ee5e6b4b0d3255bfef95601890afd80709
#
# Copyright 2018 Melon Software Ltd (UK), all rights reserved
#
AWSTemplateFormatVersion: "2010-09-09"
Description: "Creates ingest pipeline for preprocessing infrastructure"

Parameters:

    Environment:
        Type: "String"
        Description: "The name of the Environment"

    S3BucketName:
        Type: "String"
        Description: "The name of the S3 ingest bucket"

    StateMachineArn:
        Type: "String"
        Description: "The ARN of the State Machine"

    DynamodbWriteCapacity:
        Default: 1
        Description: "The write capacity of the DynamoDb table"
        MinValue: 1
        Type: "Number"

Mappings:
    TemplateVersion:
        Self: { Commit: "da39a3ee5e6b4b0d3255bfef95601890afd80709" }

Metadata:
    "AWS::CloudFormation::Interface":
        ParameterLabels:
            Environment: { default: "Environment" }
            StateMachineArn: { default: "State Machine ARN" }

Resources:

    ##########################################################################################################
    ##  IAM
    ##########################################################################################################

    LambdaTriggerRole:
        Type: "AWS::IAM::Role"
        Properties:
            AssumeRolePolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Effect: "Allow"
                    Principal: { Service: [ "lambda.amazonaws.com" ] }
                    Action: "sts:AssumeRole"
            ManagedPolicyArns:
              - "arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole"
              - "arn:aws:iam::aws:policy/service-role/AWSLambdaDynamoDBExecutionRole"
              - "arn:aws:iam::aws:policy/AWSXrayWriteOnlyAccess"
              - { "Fn::Sub": "arn:aws:iam::${AWS::AccountId}:policy/infrastructure-${Environment}-querypostgres" }
              - { Ref: "SessionEventsReadPolicy" }
              - { Ref: "SessionEventsWritePolicy" }
            Policies:
              - PolicyName: "default"
                PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Action:
                          - "cloudwatch:PutMetricData"
                          - "s3:ListBucket"
                          - "s3:GetObject"
                        Effect: "Allow"
                        Resource: "*"

                      - Action:
                          - "states:StartExecution"
                        Effect: "Allow"
                        Resource: { Ref: "StateMachineArn" }
            RoleName: { "Fn::Sub": "preprocessing-${Environment}-ingest-lambda-${AWS::Region}" }

    ##########################################################################################################
    ##  DATABASE
    ##########################################################################################################

    SessionEventsTable:
        Type: "AWS::DynamoDB::Table"
        Properties:
            TableName: { "Fn::Sub": "preprocessing-${Environment}-ingest-sessions" }
            AttributeDefinitions:
              - { AttributeName: "id", AttributeType: "S" }
              - { AttributeName: "userId", AttributeType: "S" }
              - { AttributeName: "teamId", AttributeType: "S" }
              - { AttributeName: "trainingGroupId", AttributeType: "S" }
              - { AttributeName: "eventDate", AttributeType: "S" }
            KeySchema:
              - { AttributeName: "id", KeyType: "HASH" }
            ProvisionedThroughput:
                ReadCapacityUnits: 10
                WriteCapacityUnits: { Ref: "DynamodbWriteCapacity" }
            GlobalSecondaryIndexes:
              - IndexName: "userId-eventDate"
                KeySchema:
                  - { AttributeName: "userId", KeyType: "HASH" }
                  - { AttributeName: "eventDate", KeyType: "RANGE" }
                Projection:
                    ProjectionType: "ALL"
                ProvisionedThroughput:
                    ReadCapacityUnits: 5
                    WriteCapacityUnits: { Ref: "DynamodbWriteCapacity" }
              - IndexName: "teamId-eventDate"
                KeySchema:
                  - { AttributeName: "teamId", KeyType: "HASH" }
                  - { AttributeName: "eventDate", KeyType: "RANGE" }
                Projection:
                    ProjectionType: "ALL"
                ProvisionedThroughput:
                    ReadCapacityUnits: 5
                    WriteCapacityUnits: { Ref: "DynamodbWriteCapacity" }
              - IndexName: "trainingGroupId-eventDate"
                KeySchema:
                  - { AttributeName: "trainingGroupId", KeyType: "HASH" }
                  - { AttributeName: "eventDate", KeyType: "RANGE" }
                Projection:
                    ProjectionType: "ALL"
                ProvisionedThroughput:
                    ReadCapacityUnits: 5
                    WriteCapacityUnits: { Ref: "DynamodbWriteCapacity" }
            StreamSpecification:
                StreamViewType: "NEW_AND_OLD_IMAGES"
        DeletionPolicy : "Retain"

    SessionEventsReadPolicy:
        Type: "AWS::IAM::ManagedPolicy"
        Properties:
            Description: "Allows entities to read from the preprocessing sessions table"
            ManagedPolicyName: { "Fn::Sub": "preprocessing-${Environment}-ingest-sessions-read" }
            Path: "/"
            PolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Action:
                      - "dynamodb:GetItem"
                      - "dynamodb:Query"
                    Effect: "Allow"
                    Resource:
                      - { "Fn::Sub": "${SessionEventsTable.Arn}" }
                      - { "Fn::Sub": "${SessionEventsTable.Arn}/*" }

    SessionEventsWritePolicy:
        Type: "AWS::IAM::ManagedPolicy"
        Properties:
            Description: "Allows entities to write to the preprocessing sessions table"
            ManagedPolicyName: { "Fn::Sub": "preprocessing-${Environment}-ingest-sessions-write" }
            Path: "/"
            PolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Action:
                      - "dynamodb:UpdateItem"
                      - "dynamodb:DeleteItem"
                      - "dynamodb:PutItem"
                    Effect: "Allow"
                    Resource:
                      - { "Fn::Sub": "${SessionEventsTable.Arn}" }
                      - { "Fn::Sub": "${SessionEventsTable.Arn}/*" }

    ##########################################################################################################
    ##  LAMBDA
    ##########################################################################################################

    LambdaTrigger:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: |
                    import boto3, os, datetime
                    from boto3.dynamodb.conditions import Attr
                    ddb_session_events_table = boto3.resource('dynamodb').Table(os.environ['DYNAMODB_SESSION_EVENTS_TABLE_NAME'])

                    def handler(event, _):
                        print(event)
                        record = event['Records'][0]
                        s3_bucket = record['s3']['bucket']['name']
                        s3_key = record['s3']['object']['key'].split('/')[-1]

                        s3_object = boto3.resource('s3').Object(s3_bucket, record['s3']['object']['key'])
                        upload_time = s3_object.last_modified.strftime("%Y-%m-%dT%H:%M:%SZ")
                        now_time = datetime.datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ")

                        session_event_updates = DynamodbUpdate()

                        if '_' in s3_key:
                            # A multipart upload
                            s3_basepath, part = s3_key.split('_')
                            if part == 'v1.0':
                                version = '1.0'
                            else:
                                # Assume version 2
                                version = '2.3'

                            session_event_updates.add("s3_files", {s3_key})
                            session_event_updates.set("updated_date", now_time)
                            session_event_updates.set("version", version)
                            session_event_updates.set("session_status", 'UPLOAD_IN_PROGRESS')

                            if part == 'complete' or version == '1.0':
                                # Ready for processing
                                session_event_updates.set("session_status", 'UPLOAD_COMPLETE')

                            condition_expression = Attr('id').not_exists() | Attr('session_status').is_in(['CREATE_COMPLETE', 'UPLOAD_IN_PROGRESS'])
                            ddb_session_events_table.update_item(
                                Key={'id': s3_basepath},
                                ConditionExpression=condition_expression,
                                UpdateExpression=session_event_updates.update_expression,
                                ExpressionAttributeValues=session_event_updates.parameters,
                            )
                            # TODO deal with the exception when the conditional check fails (will prevent reingesting files)

                        else:
                            # An un-suffixed file.  We don't do these any more (must be a bug)
                            return

                    class DynamodbUpdate:
                        def __init__(self):
                            self._add = set([])
                            self._set = set([])
                            self._parameters = {}

                        def set(self, field, value):
                            self._set.add("{field} = :{field}".format(field=field))
                            self._parameters[':' + field] = value

                        def add(self, field, value):
                            self._add.add("{field} :{field}".format(field=field))
                            self._parameters[':' + field] = value

                        @property
                        def update_expression(self):
                            return 'SET {} ADD {}'.format(', '.join(self._set), ', '.join(self._add))

                        @property
                        def parameters(self):
                            return self._parameters
            Environment:
                Variables:
                    DYNAMODB_SESSION_EVENTS_TABLE_NAME: { Ref: "SessionEventsTable" }
                    ENVIRONMENT: { Ref: "Environment" }
                    STATE_MACHINE_ARN: { Ref: "StateMachineArn" }
            Handler: "index.handler"
            MemorySize: "256"
            Runtime: "python3.6"
            Timeout: "60"
            Role: { "Fn::GetAtt" : [ "LambdaTriggerRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-ingest-trigger" }
            Tags:
              - { Key: "Name", Value: { "Fn::Sub": "preprocessing-${Environment}-ingest-trigger" } }
              - { Key: "Management", Value: "managed" }
              - { Key: "Project", Value: "preprocessing" }
              - { Key: "Environment", Value: { Ref: "Environment" } }
              - { Key: "Service", Value: "ingest" }

    SessionsDynamodbTriggerLambda:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: |
                    import boto3, json, os, time, urllib.request
                    from decimal import Decimal

                    def handler(event, _):
                        print(json.dumps(event))
                        for record in event['Records']:
                            new_object = load_obj(record['dynamodb'].get('NewImage', {}))
                            old_object = load_obj(record['dynamodb'].get('OldImage', {}))
                            changes = { k : (old_object.get(k, None), new_object.get(k, None)) for k, _ in set(new_object.items()).symmetric_difference(set(old_object.items())) }

                            if 'session_status' in changes and changes['session_status'][1] == 'UPLOAD_COMPLETE':
                                # Begin processing
                                print('Beginning SFN execution')
                                trigger_sfn(new_object['id'], new_object.get('version', '2.3'))

                            if 'user_id' in changes and new_object['user_id'] != '---':
                                print('Loading data from users service')
                                user = get_user_from_id(new_object['user_id'])
                                if user is not None:
                                    update_dynamodb(new_object['id'], {
                                        'team_id': user['team_id'],
                                        'training_group_ids': set(user['training_group_ids']),
                                        'user_mass': Decimal(str(user['mass']['kg'])),
                                    })

                            if 'accessory_id' in changes:
                                print('Loading data from hardware service')
                                accessory = get_accessory_from_id(new_object['accessory_id'])
                                if accessory is not None:
                                    update_dynamodb(new_object['id'], {'user_id': accessory['owner_id'] or '---'})

                    def get_accessory_from_id(accessory_id):
                        ret = make_request('https://apis.{ENVIRONMENT}.fathomai.com/hardware/accessory/{ACCESSORY_ID}'.format(**os.environ, ACCESSORY_ID=accessory_id))
                        return dict(ret).get('accessory', None)

                    def get_user_from_id(user_id):
                        ret = make_request('https://apis.{ENVIRONMENT}.fathomai.com/users/user/{USER_ID}'.format(**os.environ, USER_ID=user_id))
                        return dict(ret).get('user', None)

                    def make_request(url):
                        # TODO
                        authorisation = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIwMDAwMDAwMC0wMDAwLTQwMDAtODAwMC0wMDAwMDAwMDAwMDAifQ.B0cQFH950aef1Wi09GyooBirtCuB7tl9Rr0DPvwQwFE'
                        headers = {'Authorization': authorisation, 'Accept': 'application/json'}
                        try:
                            with urllib.request.urlopen(urllib.request.Request(url, headers=headers)) as response:
                                ret = json.loads(response.read())
                            print(json.dumps(ret))
                            return ret
                        except urllib.error.HTTPError as e:
                            return None

                    def trigger_sfn(session_id, version):
                        execution_name = '{}-{}'.format(session_id, int(time.time()))
                        boto3.client('stepfunctions').start_execution(
                            stateMachineArn=os.environ['STATE_MACHINE_ARN'],
                            name=execution_name,
                            input=json.dumps({
                                "Meta": {
                                    "ExecutionArn": "{}:{}".format(os.environ['STATE_MACHINE_ARN'], execution_name),
                                    "ExecutionName": execution_name,
                                },
                                "SourceEvent": {
                                    "SessionId": session_id,
                                    "SensorDataFileVersion": version,
                                }
                            })
                        )

                    def load_obj(record):
                        def cast(t, v):
                            return {
                                'S': lambda x: x,
                                'N': lambda x: float(x),
                                'SS': lambda x: frozenset(x),
                                'L': lambda x: tuple(x),
                            }[t](v)
                        return {attr_name: cast(*v.items()[0]) for attr_name, v in record.items()}

                    def update_dynamodb(session_id, updates):
                        update_expression = 'SET {} '.format(', '.join(["{} = :{}".format(k, k) for k in updates.keys()]))
                        values = {':' + k: v for (k, v) in updates.items()}
                        print('Updating {} with parameters {}'.format(update_expression, values))
                        boto3.resource('dynamodb').Table(os.environ['DYNAMODB_TABLE_NAME']).update_item(
                            Key={'id': session_id},
                            UpdateExpression=update_expression,
                            ExpressionAttributeValues=values,
                        )

            Environment:
                Variables:
                    DYNAMODB_TABLE_NAME: { Ref: "SessionEventsTable" }
                    ENVIRONMENT: { Ref: "Environment" }
                    STATE_MACHINE_ARN: { Ref: "StateMachineArn" }
            Handler: "index.handler"
            MemorySize: "256"
            Runtime: "python3.6"
            Timeout: "300"
            Role: { "Fn::GetAtt" : [ "LambdaTriggerRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-ingest-sessions-stream" }
            Tags:
              - { Key: "Name", Value: { "Fn::Sub": "preprocessing-${Environment}-ingest-sessions-stream" } }
              - { Key: "Management", Value: "managed" }
              - { Key: "Project", Value: "preprocessing" }
              - { Key: "Environment", Value: { Ref: "Environment" } }
              - { Key: "Service", Value: "ingest" }

    SessionsDynamodbTriggerMapping:
        Type: "AWS::Lambda::EventSourceMapping"
        Properties:
            BatchSize: 1
            Enabled: true
            EventSourceArn: { "Fn::GetAtt": [ "SessionEventsTable", "StreamArn" ] }
            FunctionName: { Ref: "SessionsDynamodbTriggerLambda" }
            StartingPosition: "LATEST"

    LambdaTriggerPermission:
        Type: "AWS::Lambda::Permission"
        Properties:
            Action: "lambda:InvokeFunction"
            FunctionName: { "Fn::GetAtt": [ "LambdaTrigger", "Arn" ] }
            Principal: "s3.amazonaws.com"
            SourceArn: { "Fn::Sub": "arn:aws:s3:::${S3BucketName}" }
            SourceAccount: { Ref : "AWS::AccountId" }

Outputs:
    TriggerLambdaArn:
        Description: "The ARN of the trigger lambda"
        Value: { "Fn::GetAtt": [ "LambdaTrigger", "Arn" ] }
    SessionEventsTableName:
        Description: "The name of the session events table"
        Value: { Ref: "SessionEventsTable" }
